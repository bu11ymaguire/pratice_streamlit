import pandas as pd
import numpy as np
import joblib
import os
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
import time

# ê²½ë¡œ ì„¤ì •
BASE_PATH = "/home/jwkim628/hello"
os.chdir(BASE_PATH)

print("=" * 80)
print("ì‹ ìš©ì¹´ë“œ ì—°ì²´ ì˜ˆì¸¡ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬")
print("=" * 80)

# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
print("\n[1] ë°ì´í„° ë¡œë“œ ì¤‘...")
df = pd.read_csv('credit_card_dataset.csv')
df.columns = df.columns.str.upper()

# ID ì»¬ëŸ¼ ì œê±°
if 'ID' in df.columns:
    df = df.drop(columns=['ID'])
if 'UNNAMED: 0' in df.columns:
    df = df.drop(columns=['UNNAMED: 0'])

df = df.fillna(0)

# Target ë¶„ë¦¬
target_col = 'DEFAULT_PAYMENT_NEXT_MONTH'
X = df.drop(target_col, axis=1)
y = df[target_col]

print(f"ë°ì´í„° í¬ê¸°: {X.shape}")
print(f"í´ë˜ìŠ¤ ë¶„í¬: {y.value_counts().to_dict()}")

# 2. ë²”ì£¼í˜•/ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì •ì˜
categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']
numeric_cols = [col for col in X.columns if col not in categorical_features]

# 3. ì¸ì½”ë”©
print("\n[2] ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© ì¤‘...")
le_dict = {}
for col in categorical_features:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
    le_dict[col] = le

# 4. Train/Test ë¶„í• 
print("\n[3] ë°ì´í„° ë¶„í•  ì¤‘...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# 5. ìŠ¤ì¼€ì¼ë§
print("\n[4] ìŠ¤ì¼€ì¼ë§ ì¤‘...")
scaler = StandardScaler()
X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])

# 6. ëª¨ë¸ íŒŒì¼ ëª©ë¡
model_files = [
    'optimal_xgboost_model.pkl',
    'optimal_lightgbm_model.pkl',
    'optimal_random_forest_model.pkl'
]

# 7. ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
print("\n" + "=" * 80)
print("ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
print("=" * 80)

results = []

for model_file in model_files:
    if not os.path.exists(model_file):
        print(f"\nâš ï¸  {model_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        continue
    
    print(f"\nğŸ“Š {model_file} í‰ê°€ ì¤‘...")
    
    # ëª¨ë¸ ë¡œë“œ
    try:
        model = joblib.load(model_file)
        model_name = model_file.replace('optimal_', '').replace('_model.pkl', '').upper()
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        continue
    
    # ì˜ˆì¸¡ ì‹œê°„ ì¸¡ì •
    start_time = time.time()
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
    prediction_time = time.time() - start_time
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None
    
    # Confusion Matrix
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    
    # ê²°ê³¼ ì €ì¥
    result = {
        'Model': model_name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'ROC-AUC': roc_auc,
        'True Negatives': tn,
        'False Positives': fp,
        'False Negatives': fn,
        'True Positives': tp,
        'Prediction Time (s)': prediction_time
    }
    results.append(result)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"  âœ“ Accuracy:  {accuracy:.4f}")
    print(f"  âœ“ Precision: {precision:.4f}")
    print(f"  âœ“ Recall:    {recall:.4f}")
    print(f"  âœ“ F1-Score:  {f1:.4f}")
    if roc_auc:
        print(f"  âœ“ ROC-AUC:   {roc_auc:.4f}")
    print(f"  âœ“ Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}")
    print(f"  âœ“ Prediction Time: {prediction_time:.4f}s")

# 8. ê²°ê³¼ ìš”ì•½
print("\n" + "=" * 80)
print("ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
print("=" * 80)

if results:
    df_results = pd.DataFrame(results)
    
    # ì†Œìˆ˜ì  í¬ë§·íŒ…
    format_dict = {
        'Accuracy': '{:.4f}',
        'Precision': '{:.4f}',
        'Recall': '{:.4f}',
        'F1-Score': '{:.4f}',
        'ROC-AUC': '{:.4f}',
        'Prediction Time (s)': '{:.4f}'
    }
    
    print("\n", df_results.to_string(index=False))
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°
    print("\n" + "-" * 80)
    print("ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸:")
    print(f"  - Accuracy:  {df_results.loc[df_results['Accuracy'].idxmax(), 'Model']}")
    print(f"  - Precision: {df_results.loc[df_results['Precision'].idxmax(), 'Model']}")
    print(f"  - Recall:    {df_results.loc[df_results['Recall'].idxmax(), 'Model']}")
    print(f"  - F1-Score:  {df_results.loc[df_results['F1-Score'].idxmax(), 'Model']}")
    if df_results['ROC-AUC'].notna().any():
        print(f"  - ROC-AUC:   {df_results.loc[df_results['ROC-AUC'].idxmax(), 'Model']}")
    
    # ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
    df_results.to_csv('benchmark_results.csv', index=False)
    print("\nğŸ’¾ ê²°ê³¼ê°€ 'benchmark_results.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("\nâš ï¸  ë²¤ì¹˜ë§ˆí¬í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

print("\n" + "=" * 80)